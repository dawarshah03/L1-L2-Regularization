# L1, L2 Regularization

## Problem
Sometimes, machine learning models work great on training data but fail on new data. This is called overfitting. We need a way to fix that.

## Solution
We used L1 (Lasso) and L2 (Ridge) regularization with Logistic Regression to reduce overfitting. Regularization makes the model simpler by reducing big weights.

## What Are We Finding
We checked how the model behaves when we:

Change the regularization strength (C value)

Compare L1 vs L2 regularization

See how accuracy and weights change

## Why This Project
This helps us learn how to make models better and avoid overfitting. Also shows how L1 and L2 are different.
